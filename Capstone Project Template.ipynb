{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "This project will build up a data warehouse as a single-source-of-truth database by combining four data sets containing immigration data, airport codes, demographics of US cities and global temperature data. \n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import configparser\n",
    "import os\n",
    "from datetime import datetime\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col, count, sum, mean, round, upper, lower\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear, date_format, monotonically_increasing_id\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.types import DoubleType, StringType, IntegerType, FloatType, DateType\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read_file(open('dl.cfg'))\n",
    "\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = config['AWS']['AWS_ACCESS_KEY_ID']\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = config['AWS']['AWS_SECRET_ACCESS_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#spark = SparkSession.builder.\\\n",
    "#config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\").\\\n",
    "#config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11\").\\\n",
    "#enableHiveSupport().getOrCreate()\n",
    "\n",
    "#df_spark = spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#write to parquet\n",
    "#df_spark.write.parquet(\"sas_data\")\n",
    "#df_spark=spark.read.parquet(\"sas_data\")\n",
    "#df_spark.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "###### Below SparkSession configurations should be done to be able to write into S3 Buckets (according to the Spark version over the server)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder\\\n",
    "                    .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\")\\\n",
    "                    .enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use? etc>\n",
    "\n",
    "In this project we will gather the data from four differnt data sources. here you are the steps that will be followed:\n",
    "1. Read and load into staging Dataframes\n",
    "2. Apply cleansing over all those DFs\n",
    "3. Perform some ETL trasformation rules using pyspark\n",
    "4. Model them into Fact & Dimention tables using start schema\n",
    "5. Write those DFs into S3 buckets\n",
    "6. Extract again and apply Data Quality checks\n",
    "\n",
    "#### Describe and Gather Data \n",
    "Describe the data sets you're using. Where did it come from? What type of information is included? \n",
    "\n",
    "- i94 Immigration Sample Data: Sample data of immigration records from the US National Tourism and Trade Office. This is the main data source that will serve as the Fact table in the schema. This data comes from https://travel.trade.gov/research/reports/i94/historical/2016.html.\n",
    "- World Temperature Data world_temperature. This dataset contains temperature data in various cities from the 1700’s to 2013. Although the data is only recorded until 2013, we can use this as an average/gauge of temperature in 2017. This data comes from https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data.\n",
    "- US City Demographic Data: Data about the demographics of US cities. This dataset includes information on the population of all US cities such as race, household size and gender. This data comes from https://public.opendatasoft.com/explore/dataset/us-cities-demographics/export/.\n",
    "- Airport Codes: This table contains the airport codes for the airports in corresponding cities. This data comes from https://datahub.io/core/airport-codes#data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### TEMPERATURE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "fname = '../../data2/GlobalLandTemperaturesByCity.csv'\n",
    "temperature_df_orig = pd.read_csv(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.737</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt  AverageTemperature  AverageTemperatureUncertainty   City  \\\n",
       "0  1743-11-01               6.068                          1.737  Århus   \n",
       "1  1743-12-01                 NaN                            NaN  Århus   \n",
       "2  1744-01-01                 NaN                            NaN  Århus   \n",
       "3  1744-02-01                 NaN                            NaN  Århus   \n",
       "4  1744-03-01                 NaN                            NaN  Århus   \n",
       "\n",
       "   Country Latitude Longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  \n",
       "3  Denmark   57.05N    10.33E  \n",
       "4  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature_df_orig.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Due to performance, I'll restrich over the Temprature readings in USA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dt                               687289\n",
       "AverageTemperature               661524\n",
       "AverageTemperatureUncertainty    661524\n",
       "City                             687289\n",
       "Country                          687289\n",
       "Latitude                         687289\n",
       "Longitude                        687289\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature_df = temperature_df_orig[temperature_df_orig['Country'] == 'United States']\n",
    "temperature_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### AIRPORT CODES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "airport_codes = 'airport-codes_csv.csv'\n",
    "airport_df = pd.read_csv(airport_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>450.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>00AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999146, 59.94919968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>820.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>00AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AL</td>\n",
       "      <td>-86.77030181884766, 34.86479949951172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AR</td>\n",
       "      <td>closed</td>\n",
       "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
       "      <td>237.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AR</td>\n",
       "      <td>Newport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-91.254898, 35.6087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                                name  elevation_ft  \\\n",
       "0   00A       heliport                   Total Rf Heliport          11.0   \n",
       "1  00AA  small_airport                Aero B Ranch Airport        3435.0   \n",
       "2  00AK  small_airport                        Lowell Field         450.0   \n",
       "3  00AL  small_airport                        Epps Airpark         820.0   \n",
       "4  00AR         closed  Newport Hospital & Clinic Heliport         237.0   \n",
       "\n",
       "  continent iso_country iso_region  municipality gps_code iata_code  \\\n",
       "0       NaN          US      US-PA      Bensalem      00A       NaN   \n",
       "1       NaN          US      US-KS         Leoti     00AA       NaN   \n",
       "2       NaN          US      US-AK  Anchor Point     00AK       NaN   \n",
       "3       NaN          US      US-AL       Harvest     00AL       NaN   \n",
       "4       NaN          US      US-AR       Newport      NaN       NaN   \n",
       "\n",
       "  local_code                            coordinates  \n",
       "0        00A     -74.93360137939453, 40.07080078125  \n",
       "1       00AA                 -101.473911, 38.704022  \n",
       "2       00AK            -151.695999146, 59.94919968  \n",
       "3       00AL  -86.77030181884766, 34.86479949951172  \n",
       "4        NaN                    -91.254898, 35.6087  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### IMMIGRATION DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "immigration_data = 'immigration_data_sample.csv'\n",
    "immigration_df = pd.read_csv(immigration_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2027561</td>\n",
       "      <td>4084316.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>20566.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>07202016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JL</td>\n",
       "      <td>5.658267e+10</td>\n",
       "      <td>00782</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2171295</td>\n",
       "      <td>4422636.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>MCA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>10222016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>*GA</td>\n",
       "      <td>9.436200e+10</td>\n",
       "      <td>XBLNG</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>589494</td>\n",
       "      <td>1195600.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>OGG</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>07052016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LH</td>\n",
       "      <td>5.578047e+10</td>\n",
       "      <td>00464</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2631158</td>\n",
       "      <td>5291768.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20572.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>10272016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QR</td>\n",
       "      <td>9.478970e+10</td>\n",
       "      <td>00739</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3032257</td>\n",
       "      <td>985523.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>CHM</td>\n",
       "      <td>20550.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>07042016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.232257e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  \\\n",
       "0     2027561  4084316.0  2016.0     4.0   209.0   209.0     HHW  20566.0   \n",
       "1     2171295  4422636.0  2016.0     4.0   582.0   582.0     MCA  20567.0   \n",
       "2      589494  1195600.0  2016.0     4.0   148.0   112.0     OGG  20551.0   \n",
       "3     2631158  5291768.0  2016.0     4.0   297.0   297.0     LOS  20572.0   \n",
       "4     3032257   985523.0  2016.0     4.0   111.0   111.0     CHM  20550.0   \n",
       "\n",
       "   i94mode i94addr    ...     entdepu  matflag  biryear   dtaddto  gender  \\\n",
       "0      1.0      HI    ...         NaN        M   1955.0  07202016       F   \n",
       "1      1.0      TX    ...         NaN        M   1990.0  10222016       M   \n",
       "2      1.0      FL    ...         NaN        M   1940.0  07052016       M   \n",
       "3      1.0      CA    ...         NaN        M   1991.0  10272016       M   \n",
       "4      3.0      NY    ...         NaN        M   1997.0  07042016       F   \n",
       "\n",
       "  insnum airline        admnum  fltno  visatype  \n",
       "0    NaN      JL  5.658267e+10  00782        WT  \n",
       "1    NaN     *GA  9.436200e+10  XBLNG        B2  \n",
       "2    NaN      LH  5.578047e+10  00464        WT  \n",
       "3    NaN      QR  9.478970e+10  00739        B2  \n",
       "4    NaN     NaN  4.232257e+10   LAND        WT  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immigration_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### US CITIES DEMOGRAPHICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "us_cities_demographics = 'us-cities-demographics.csv'\n",
    "demographics_df = spark.read.csv(us_cities_demographics, inferSchema=True, header=True, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601</td>\n",
       "      <td>41862</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562</td>\n",
       "      <td>30908</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129</td>\n",
       "      <td>49500</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147</td>\n",
       "      <td>32935</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040</td>\n",
       "      <td>46799</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819</td>\n",
       "      <td>8229</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127</td>\n",
       "      <td>87105</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821</td>\n",
       "      <td>33878</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040</td>\n",
       "      <td>143873</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829</td>\n",
       "      <td>86253</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State  Median Age  Male Population  \\\n",
       "0     Silver Spring       Maryland        33.8            40601   \n",
       "1            Quincy  Massachusetts        41.0            44129   \n",
       "2            Hoover        Alabama        38.5            38040   \n",
       "3  Rancho Cucamonga     California        34.5            88127   \n",
       "4            Newark     New Jersey        34.6           138040   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0              41862             82463                1562         30908   \n",
       "1              49500             93629                4147         32935   \n",
       "2              46799             84839                4819          8229   \n",
       "3              87105            175232                5821         33878   \n",
       "4             143873            281913                5829         86253   \n",
       "\n",
       "   Average Household Size State Code                       Race  Count  \n",
       "0                    2.60         MD         Hispanic or Latino  25924  \n",
       "1                    2.39         MA                      White  58723  \n",
       "2                    2.58         AL                      Asian   4759  \n",
       "3                    3.18         CA  Black or African-American  24437  \n",
       "4                    2.73         NJ                      White  76402  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographics_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data:\n",
    "- Drop rows containing all values with NULL\n",
    "- Drop duplicate values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Performing cleaning tasks here\n",
    "# Delete those missing all values rows and then duplicates in all DFs\n",
    "# Temperature DF\n",
    "temperature_clean = temperature_df.dropna(how='all')\n",
    "temperature_clean = temperature_clean.drop_duplicates()\n",
    "\n",
    "# Airport DF\n",
    "airport_clean = airport_df.dropna(how='all')\n",
    "airport_clean = airport_clean.drop_duplicates()\n",
    "\n",
    "# Immigration DF\n",
    "immigration_clean = immigration_df.dropna(how='all')\n",
    "immigration_clean = immigration_clean.drop_duplicates()\n",
    "\n",
    "# Demographics DF\n",
    "demographics_clean = demographics_df.dropna(how='all')\n",
    "demographics_clean = demographics_clean.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "According to Kimball Modelling and as per the nature of the 4 combined Data Sources. The main target of combining those 4 Data Sources is to track the immigration actions into the USA. Accordingly:\n",
    "\n",
    "- 1. Identify the Facts:\n",
    "    - Fact tables focus on the occurrences of a singular business process, and have a one-to-one relationship with the dimention tables.\n",
    "    - The fact table identified in this project is:\n",
    "        - immigration_fact\n",
    "        \n",
    "- 2. Identify the Dimensions:\n",
    "    - Dimension tables provide any quantitative or metric around the fact event or business process.\n",
    "    - The dimensions identified in this project are:\n",
    "        - migrant_dim\n",
    "        - status_dim\n",
    "        - visa_dim\n",
    "        - state_dim\n",
    "        - time_dim\n",
    "        - airport_codes\n",
    "        - temperature_dim\n",
    "        - country_codes\n",
    "        - country_temperature\n",
    "    \n",
    "The above mentioned tables will be developed in a Relational Database Management System to form a Star Schema, which can be used in Data analytics and BI insights activities.\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model:\n",
    "1. Read and load into staging Dataframes\n",
    "2. Apply cleansing over all those DFs\n",
    "3. Perform some ETL trasformation rules using pyspark\n",
    "4. Model them into Fact & Dimention tables using start schema\n",
    "5. Write those DFs into S3 buckets\n",
    "6. Extract again and apply Data Quality checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 687289 entries, 47555 to 8439246\n",
      "Data columns (total 7 columns):\n",
      "dt                               687289 non-null object\n",
      "AverageTemperature               661524 non-null float64\n",
      "AverageTemperatureUncertainty    661524 non-null float64\n",
      "City                             687289 non-null object\n",
      "Country                          687289 non-null object\n",
      "Latitude                         687289 non-null object\n",
      "Longitude                        687289 non-null object\n",
      "dtypes: float64(2), object(5)\n",
      "memory usage: 41.9+ MB\n"
     ]
    }
   ],
   "source": [
    "temperature_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1820-01-01</td>\n",
       "      <td>2.101</td>\n",
       "      <td>3.217</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1820-02-01</td>\n",
       "      <td>6.926</td>\n",
       "      <td>2.853</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1820-03-01</td>\n",
       "      <td>10.767</td>\n",
       "      <td>2.395</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1820-04-01</td>\n",
       "      <td>17.989</td>\n",
       "      <td>2.202</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1820-05-01</td>\n",
       "      <td>21.809</td>\n",
       "      <td>2.036</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt  AverageTemperature  AverageTemperatureUncertainty     City  \\\n",
       "0  1820-01-01               2.101                          3.217  Abilene   \n",
       "1  1820-02-01               6.926                          2.853  Abilene   \n",
       "2  1820-03-01              10.767                          2.395  Abilene   \n",
       "3  1820-04-01              17.989                          2.202  Abilene   \n",
       "4  1820-05-01              21.809                          2.036  Abilene   \n",
       "\n",
       "         Country Latitude Longitude  \n",
       "0  United States   32.95N   100.53W  \n",
       "1  United States   32.95N   100.53W  \n",
       "2  United States   32.95N   100.53W  \n",
       "3  United States   32.95N   100.53W  \n",
       "4  United States   32.95N   100.53W  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create schema for Temperature\n",
    "temperature_schema = StructType([StructField(\"dt\", StringType(), True)\\\n",
    "                          ,StructField(\"AverageTemperature\", FloatType(), True)\\\n",
    "                          ,StructField(\"AverageTemperatureUncertainty\", FloatType(), True)\\\n",
    "                          ,StructField(\"City\", StringType(), True)\\\n",
    "                          ,StructField(\"Country\", StringType(), True)\\\n",
    "                          ,StructField(\"Latitude\", StringType(), True)\\\n",
    "                          ,StructField(\"Longitude\", StringType(), True)])\n",
    "\n",
    "temperature_spark = spark.createDataFrame(temperature_clean, schema=temperature_schema)\n",
    "\n",
    "temperature_spark.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 55075 entries, 0 to 55074\n",
      "Data columns (total 12 columns):\n",
      "ident           55075 non-null object\n",
      "type            55075 non-null object\n",
      "name            55075 non-null object\n",
      "elevation_ft    48069 non-null float64\n",
      "continent       27356 non-null object\n",
      "iso_country     54828 non-null object\n",
      "iso_region      55075 non-null object\n",
      "municipality    49399 non-null object\n",
      "gps_code        41030 non-null object\n",
      "iata_code       9189 non-null object\n",
      "local_code      28686 non-null object\n",
      "coordinates     55075 non-null object\n",
      "dtypes: float64(1), object(11)\n",
      "memory usage: 5.5+ MB\n"
     ]
    }
   ],
   "source": [
    "airport_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>450.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>00AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999146, 59.94919968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>820.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>00AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AL</td>\n",
       "      <td>-86.77030181884766, 34.86479949951172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AR</td>\n",
       "      <td>closed</td>\n",
       "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
       "      <td>237.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AR</td>\n",
       "      <td>Newport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-91.254898, 35.6087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                                name  elevation_ft  \\\n",
       "0   00A       heliport                   Total Rf Heliport          11.0   \n",
       "1  00AA  small_airport                Aero B Ranch Airport        3435.0   \n",
       "2  00AK  small_airport                        Lowell Field         450.0   \n",
       "3  00AL  small_airport                        Epps Airpark         820.0   \n",
       "4  00AR         closed  Newport Hospital & Clinic Heliport         237.0   \n",
       "\n",
       "  continent iso_country iso_region  municipality gps_code iata_code  \\\n",
       "0       NaN          US      US-PA      Bensalem      00A       NaN   \n",
       "1       NaN          US      US-KS         Leoti     00AA       NaN   \n",
       "2       NaN          US      US-AK  Anchor Point     00AK       NaN   \n",
       "3       NaN          US      US-AL       Harvest     00AL       NaN   \n",
       "4       NaN          US      US-AR       Newport      NaN       NaN   \n",
       "\n",
       "  local_code                            coordinates  \n",
       "0        00A     -74.93360137939453, 40.07080078125  \n",
       "1       00AA                 -101.473911, 38.704022  \n",
       "2       00AK            -151.695999146, 59.94919968  \n",
       "3       00AL  -86.77030181884766, 34.86479949951172  \n",
       "4        NaN                    -91.254898, 35.6087  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create schema for Airport codes\n",
    "airport_codes_schema = StructType([StructField(\"ident\", StringType(), True)\\\n",
    "                        ,StructField(\"type\", StringType(), True)\\\n",
    "                        ,StructField(\"name\", StringType(), True)\\\n",
    "                        ,StructField(\"elevation_ft\", FloatType(), True)\\\n",
    "                        ,StructField(\"continent\", StringType(), True)\\\n",
    "                        ,StructField(\"iso_country\", StringType(), True)\\\n",
    "                        ,StructField(\"iso_region\", StringType(), True)\\\n",
    "                        ,StructField(\"municipality\", StringType(), True)\\\n",
    "                        ,StructField(\"gps_code\", StringType(), True)\\\n",
    "                        ,StructField(\"iata_code\", StringType(), True)\\\n",
    "                        ,StructField(\"local_code\", StringType(), True)\\\n",
    "                        ,StructField(\"coordinates\", StringType(), True)])\n",
    "\n",
    "airport_codes_spark = spark.createDataFrame(airport_clean, schema=airport_codes_schema)\n",
    "\n",
    "airport_codes_spark.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1000 entries, 0 to 999\n",
      "Data columns (total 29 columns):\n",
      "Unnamed: 0    1000 non-null int64\n",
      "cicid         1000 non-null float64\n",
      "i94yr         1000 non-null float64\n",
      "i94mon        1000 non-null float64\n",
      "i94cit        1000 non-null float64\n",
      "i94res        1000 non-null float64\n",
      "i94port       1000 non-null object\n",
      "arrdate       1000 non-null float64\n",
      "i94mode       1000 non-null float64\n",
      "i94addr       941 non-null object\n",
      "depdate       951 non-null float64\n",
      "i94bir        1000 non-null float64\n",
      "i94visa       1000 non-null float64\n",
      "count         1000 non-null float64\n",
      "dtadfile      1000 non-null int64\n",
      "visapost      382 non-null object\n",
      "occup         4 non-null object\n",
      "entdepa       1000 non-null object\n",
      "entdepd       954 non-null object\n",
      "entdepu       0 non-null float64\n",
      "matflag       954 non-null object\n",
      "biryear       1000 non-null float64\n",
      "dtaddto       1000 non-null object\n",
      "gender        859 non-null object\n",
      "insnum        35 non-null float64\n",
      "airline       967 non-null object\n",
      "admnum        1000 non-null float64\n",
      "fltno         992 non-null object\n",
      "visatype      1000 non-null object\n",
      "dtypes: float64(15), int64(2), object(12)\n",
      "memory usage: 234.4+ KB\n"
     ]
    }
   ],
   "source": [
    "immigration_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2027561</td>\n",
       "      <td>4084316.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>20566.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>07202016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JL</td>\n",
       "      <td>5.658268e+10</td>\n",
       "      <td>00782</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2171295</td>\n",
       "      <td>4422636.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>MCA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>10222016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>*GA</td>\n",
       "      <td>9.436199e+10</td>\n",
       "      <td>XBLNG</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>589494</td>\n",
       "      <td>1195600.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>OGG</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>07052016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LH</td>\n",
       "      <td>5.578047e+10</td>\n",
       "      <td>00464</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2631158</td>\n",
       "      <td>5291768.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20572.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>10272016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QR</td>\n",
       "      <td>9.478970e+10</td>\n",
       "      <td>00739</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3032257</td>\n",
       "      <td>985523.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>CHM</td>\n",
       "      <td>20550.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>07042016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.232257e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  \\\n",
       "0  2027561  4084316.0  2016.0     4.0   209.0   209.0     HHW  20566.0   \n",
       "1  2171295  4422636.0  2016.0     4.0   582.0   582.0     MCA  20567.0   \n",
       "2   589494  1195600.0  2016.0     4.0   148.0   112.0     OGG  20551.0   \n",
       "3  2631158  5291768.0  2016.0     4.0   297.0   297.0     LOS  20572.0   \n",
       "4  3032257   985523.0  2016.0     4.0   111.0   111.0     CHM  20550.0   \n",
       "\n",
       "   i94mode i94addr    ...     entdepu  matflag  biryear   dtaddto gender  \\\n",
       "0      1.0      HI    ...         NaN        M   1955.0  07202016      F   \n",
       "1      1.0      TX    ...         NaN        M   1990.0  10222016      M   \n",
       "2      1.0      FL    ...         NaN        M   1940.0  07052016      M   \n",
       "3      1.0      CA    ...         NaN        M   1991.0  10272016      M   \n",
       "4      3.0      NY    ...         NaN        M   1997.0  07042016      F   \n",
       "\n",
       "  insnum airline        admnum  fltno  visatype  \n",
       "0    NaN      JL  5.658268e+10  00782        WT  \n",
       "1    NaN     *GA  9.436199e+10  XBLNG        B2  \n",
       "2    NaN      LH  5.578047e+10  00464        WT  \n",
       "3    NaN      QR  9.478970e+10  00739        B2  \n",
       "4    NaN     NaN  4.232257e+10   LAND        WT  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create schema for immigration DF\n",
    "immigration_schema = StructType([StructField(\"0\", IntegerType(), True)\\\n",
    "                          ,StructField(\"cicid\", FloatType(), True)\\\n",
    "                          ,StructField(\"i94yr\", FloatType(), True)\\\n",
    "                          ,StructField(\"i94mon\", FloatType(), True)\\\n",
    "                          ,StructField(\"i94cit\", FloatType(), True)\\\n",
    "                          ,StructField(\"i94res\", FloatType(), True)\\\n",
    "                          ,StructField(\"i94port\", StringType(), True)\\\n",
    "                          ,StructField(\"arrdate\", FloatType(), True)\\\n",
    "                          ,StructField(\"i94mode\", FloatType(), True)\\\n",
    "                          ,StructField(\"i94addr\", StringType(), True)\\\n",
    "                          ,StructField(\"depdate\", FloatType(), True)\\\n",
    "                          ,StructField(\"i94bir\", FloatType(), True)\\\n",
    "                          ,StructField(\"i94visa\", FloatType(), True)\\\n",
    "                          ,StructField(\"count\", FloatType(), True)\\\n",
    "                          ,StructField(\"dtadfile\", StringType(), True)\\\n",
    "                          ,StructField(\"visapost\", StringType(), True)\\\n",
    "                          ,StructField(\"occup\", StringType(), True)\\\n",
    "                          ,StructField(\"entdepa\", StringType(), True)\\\n",
    "                          ,StructField(\"entdepd\", StringType(), True)\\\n",
    "                          ,StructField(\"entdepu\", FloatType(), True)\\\n",
    "                          ,StructField(\"matflag\", StringType(), True)\\\n",
    "                          ,StructField(\"biryear\", FloatType(), True)\\\n",
    "                          ,StructField(\"dtaddto\", StringType(), True)\\\n",
    "                          ,StructField(\"gender\", StringType(), True)\\\n",
    "                          ,StructField(\"insnum\", FloatType(), True)\\\n",
    "                          ,StructField(\"airline\", StringType(), True)\\\n",
    "                          ,StructField(\"admnum\", FloatType(), True)\\\n",
    "                          ,StructField(\"fltno\", StringType(), True)\\\n",
    "                          ,StructField(\"visatype\", StringType(), True)])\n",
    "\n",
    "immigration_spark = spark.createDataFrame(immigration_clean, schema=immigration_schema)\n",
    "\n",
    "immigration_spark.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2891 entries, 0 to 2890\n",
      "Data columns (total 12 columns):\n",
      "City                      2891 non-null object\n",
      "State                     2891 non-null object\n",
      "Median Age                2891 non-null float64\n",
      "Male Population           2888 non-null float64\n",
      "Female Population         2888 non-null float64\n",
      "Total Population          2891 non-null int32\n",
      "Number of Veterans        2878 non-null float64\n",
      "Foreign-born              2878 non-null float64\n",
      "Average Household Size    2875 non-null float64\n",
      "State Code                2891 non-null object\n",
      "Race                      2891 non-null object\n",
      "Count                     2891 non-null int32\n",
      "dtypes: float64(6), int32(2), object(4)\n",
      "memory usage: 248.5+ KB\n"
     ]
    }
   ],
   "source": [
    "demographics_clean.toPandas().info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Maple Grove</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>38.599998</td>\n",
       "      <td>31780.0</td>\n",
       "      <td>36601.0</td>\n",
       "      <td>68381</td>\n",
       "      <td>2943.0</td>\n",
       "      <td>7645.0</td>\n",
       "      <td>2.64</td>\n",
       "      <td>MN</td>\n",
       "      <td>White</td>\n",
       "      <td>59683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Concord</td>\n",
       "      <td>California</td>\n",
       "      <td>39.599998</td>\n",
       "      <td>62310.0</td>\n",
       "      <td>66358.0</td>\n",
       "      <td>128668</td>\n",
       "      <td>6287.0</td>\n",
       "      <td>37428.0</td>\n",
       "      <td>2.72</td>\n",
       "      <td>CA</td>\n",
       "      <td>White</td>\n",
       "      <td>92575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Highlands Ranch</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>39.599998</td>\n",
       "      <td>49186.0</td>\n",
       "      <td>53281.0</td>\n",
       "      <td>102467</td>\n",
       "      <td>4840.0</td>\n",
       "      <td>8827.0</td>\n",
       "      <td>2.72</td>\n",
       "      <td>CO</td>\n",
       "      <td>Asian</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Asheville</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>37.900002</td>\n",
       "      <td>42100.0</td>\n",
       "      <td>46407.0</td>\n",
       "      <td>88507</td>\n",
       "      <td>4973.0</td>\n",
       "      <td>6630.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>NC</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "      <td>496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Westland</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>39.900002</td>\n",
       "      <td>37742.0</td>\n",
       "      <td>44253.0</td>\n",
       "      <td>81995</td>\n",
       "      <td>4756.0</td>\n",
       "      <td>6429.0</td>\n",
       "      <td>2.41</td>\n",
       "      <td>MI</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>16422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              City           State  Median Age  Male Population  \\\n",
       "0      Maple Grove       Minnesota   38.599998          31780.0   \n",
       "1          Concord      California   39.599998          62310.0   \n",
       "2  Highlands Ranch        Colorado   39.599998          49186.0   \n",
       "3        Asheville  North Carolina   37.900002          42100.0   \n",
       "4         Westland        Michigan   39.900002          37742.0   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0            36601.0             68381              2943.0        7645.0   \n",
       "1            66358.0            128668              6287.0       37428.0   \n",
       "2            53281.0            102467              4840.0        8827.0   \n",
       "3            46407.0             88507              4973.0        6630.0   \n",
       "4            44253.0             81995              4756.0        6429.0   \n",
       "\n",
       "   Average Household Size State Code                               Race  Count  \n",
       "0                    2.64         MN                              White  59683  \n",
       "1                    2.72         CA                              White  92575  \n",
       "2                    2.72         CO                              Asian   5650  \n",
       "3                    2.18         NC  American Indian and Alaska Native    496  \n",
       "4                    2.41         MI          Black or African-American  16422  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create schema for demographic\n",
    "demographics_schema = StructType([StructField(\"City\", StringType(), True)\\\n",
    "                        ,StructField(\"State\", StringType(), True)\\\n",
    "                        ,StructField(\"Median Age\", FloatType(), True)\\\n",
    "                        ,StructField(\"Male Population\", FloatType(), True)\\\n",
    "                        ,StructField(\"Female Population\", FloatType(), True)\\\n",
    "                        ,StructField(\"Total Population\", IntegerType(), True)\\\n",
    "                        ,StructField(\"Number of Veterans\", FloatType(), True)\\\n",
    "                        ,StructField(\"Foreign-born\", FloatType(), True)\\\n",
    "                        ,StructField(\"Average Household Size\", FloatType(), True)\\\n",
    "                        ,StructField(\"State Code\", StringType(), True)\\\n",
    "                        ,StructField(\"Race\", StringType(), True)\\\n",
    "                        ,StructField(\"Count\", IntegerType(), True)])\n",
    "\n",
    "demographics_spark = spark.createDataFrame(demographics_clean.toPandas(), schema=demographics_schema)\n",
    "\n",
    "demographics_spark.toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Wrinting the tables into Parquet and upload over S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Migrant dimention table writing has been completed!\n"
     ]
    }
   ],
   "source": [
    "migrant_dim = immigration_spark.withColumn(\"migrant_id\", monotonically_increasing_id()) \\\n",
    "                      .select([\"migrant_id\", \"biryear\", \"gender\"]) \\\n",
    "                      .withColumnRenamed(\"biryear\", \"birth_year\")\\\n",
    "                      .dropDuplicates([\"birth_year\", \"gender\"])\n",
    "\n",
    "migrant_dim.write.parquet(\"s3a://udacity-datalake-msaied2/Project6_Capstone/migrant.parquet\", mode=\"overwrite\")\n",
    "print(\"Migrant dimention table writing has been completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status dimention table writing has been completed!\n"
     ]
    }
   ],
   "source": [
    "status_dim = immigration_spark.withColumn(\"status_flag_id\", monotonically_increasing_id()) \\\n",
    "                .select([\"status_flag_id\", \"entdepa\", \"entdepd\", \"matflag\"]) \\\n",
    "                .withColumnRenamed(\"entdepa\", \"arrival_flag\")\\\n",
    "                .withColumnRenamed(\"entdepd\", \"departure_flag\")\\\n",
    "                .withColumnRenamed(\"matflag\", \"match_flag\")\\\n",
    "                .dropDuplicates([\"arrival_flag\", \"departure_flag\", \"match_flag\"])\n",
    "\n",
    "status_dim.write.parquet(\"s3a://udacity-datalake-msaied2/Project6_Capstone/status.parquet\", mode=\"overwrite\")\n",
    "print(\"Status dimention table writing has been completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visa dimention table writing has been completed!\n"
     ]
    }
   ],
   "source": [
    "visa_dim = immigration_spark.withColumn(\"visa_id\", monotonically_increasing_id()) \\\n",
    "                .select([\"visa_id\",\"i94visa\", \"visatype\", \"visapost\"]) \\\n",
    "                .dropDuplicates([\"i94visa\", \"visatype\", \"visapost\"])\n",
    "\n",
    "visa_dim.write.parquet(\"s3a://udacity-datalake-msaied2/Project6_Capstone/visa.parquet\", mode=\"overwrite\")\n",
    "print(\"Visa dimention table writing has been completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State dimention table writing has been completed!\n"
     ]
    }
   ],
   "source": [
    "state_dim = demographics_spark.select([\"State Code\", \"State\", \"Median Age\", \"Male Population\", \"Female Population\", \"Total Population\", \"Average Household Size\",\\\n",
    "                          \"Foreign-born\", \"Race\", \"Count\"])\\\n",
    "                .withColumnRenamed(\"State Code\", \"state_code\")\\\n",
    "                .withColumnRenamed(\"Median Age\", \"median_age\")\\\n",
    "                .withColumnRenamed(\"Male Population\", \"male_population\")\\\n",
    "                .withColumnRenamed(\"Female Population\", \"female_population\")\\\n",
    "                .withColumnRenamed(\"Total Population\", \"total_population\")\\\n",
    "                .withColumnRenamed(\"Average Household Size\", \"average_household_size\")\\\n",
    "                .withColumnRenamed(\"Foreign-born\", \"foreign_born\")\n",
    "\n",
    "state_dim = state_dim.groupBy(col(\"state_code\"), col(\"State\").alias(\"state\")).agg(\n",
    "                        round(mean('median_age'), 2).alias(\"median_age\"),\\\n",
    "                        sum(\"total_population\").alias(\"total_population\"),\\\n",
    "                        sum(\"male_population\").alias(\"male_population\"), \\\n",
    "                        sum(\"female_population\").alias(\"female_population\"),\\\n",
    "                        sum(\"foreign_born\").alias(\"foreign_born\"), \\\n",
    "                        round(mean(\"average_household_size\"),2).alias(\"average_household_size\")\n",
    "                        ).dropna()\n",
    "\n",
    "state_dim.write.parquet(\"s3a://udacity-datalake-msaied2/Project6_Capstone/state.parquet\", mode=\"overwrite\")\n",
    "print(\"State dimention table writing has been completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time dimention table writing has been completed!\n"
     ]
    }
   ],
   "source": [
    "def convert_datetime(x):\n",
    "    try:\n",
    "        start = datetime(1960, 1, 1)\n",
    "        return start + timedelta(days=int(x))\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "udf_datetime_conversion = udf(lambda x: convert_datetime(x), DateType())\n",
    "\n",
    "time_dim = immigration_spark.select([\"arrdate\"])\\\n",
    "                .withColumn(\"arrival_date\", udf_datetime_conversion(\"arrdate\")) \\\n",
    "                .withColumn('day', F.dayofmonth('arrival_date')) \\\n",
    "                .withColumn('month', F.month('arrival_date')) \\\n",
    "                .withColumn('year', F.year('arrival_date')) \\\n",
    "                .withColumn('week', F.weekofyear('arrival_date')) \\\n",
    "                .withColumn('weekday', F.dayofweek('arrival_date'))\\\n",
    "                .select([\"arrdate\", \"arrival_date\", \"day\", \"month\", \"year\", \"week\", \"weekday\"])\\\n",
    "                .dropDuplicates([\"arrdate\"])\n",
    "\n",
    "time_dim.write.parquet(\"s3a://udacity-datalake-msaied2/Project6_Capstone/time.parquet\", mode=\"overwrite\")\n",
    "print(\"Time dimention table writing has been completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Airport_Codes dimention table writing has been completed!\n"
     ]
    }
   ],
   "source": [
    "airport_codes = airport_codes_spark.select([\"ident\", \"type\", \"iata_code\", \"name\", \"iso_country\", \"iso_region\", \"municipality\", \"gps_code\", \"coordinates\", \"elevation_ft\"])\\\n",
    "                .dropDuplicates([\"ident\"])\n",
    "\n",
    "airport_codes.write.parquet(\"s3a://udacity-datalake-msaied2/Project6_Capstone/airport_codes.parquet\", mode=\"overwrite\")\n",
    "print(\"Airport_Codes dimention table writing has been completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature dimention table writing has been completed!\n"
     ]
    }
   ],
   "source": [
    "temperature_dim = temperature_spark.groupBy(col(\"Country\").alias(\"country\")).agg(\n",
    "                round(mean('AverageTemperature'), 2).alias(\"average_temperature\"),\\\n",
    "                round(mean(\"AverageTemperatureUncertainty\"),2).alias(\"average_temperature_uncertainty\")\n",
    "                ).dropna()\\\n",
    "                .withColumn(\"temperature_id\", monotonically_increasing_id()) \\\n",
    "                .select([\"temperature_id\", \"country\", \"average_temperature\", \"average_temperature_uncertainty\"])\n",
    "\n",
    "temperature_dim.write.parquet(\"s3a://udacity-datalake-msaied2/Project6_Capstone/temperature.parquet\", mode=\"overwrite\")\n",
    "print(\"Temperature dimention table writing has been completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open(\"I94_SAS_Labels_Descriptions.SAS\") as f:\n",
    "    contents = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "country_code = {}\n",
    "for countries in contents[10:298]:\n",
    "    pair = countries.split('=')\n",
    "    code, country = pair[0].strip(), pair[1].strip().strip(\"'\")\n",
    "    country_code[code] = country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>236</td>\n",
       "      <td>AFGHANISTAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>ALBANIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>ALGERIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>102</td>\n",
       "      <td>ANDORRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>324</td>\n",
       "      <td>ANGOLA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  code      country\n",
       "0  236  AFGHANISTAN\n",
       "1  101      ALBANIA\n",
       "2  316      ALGERIA\n",
       "3  102      ANDORRA\n",
       "4  324       ANGOLA"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_country_code = pd.DataFrame(list(country_code.items()), columns=['code', 'country'])\n",
    "df_country_code.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country dimention table writing has been completed!\n"
     ]
    }
   ],
   "source": [
    "country_spark = spark.createDataFrame(df_country_code)\n",
    "country_spark.head()\n",
    "\n",
    "country_spark.write.parquet(\"s3a://udacity-datalake-msaied2/Project6_Capstone/country.parquet\", mode=\"overwrite\")\n",
    "print(\"Country dimention table writing has been completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country_Temperature dimention table writing has been completed!\n"
     ]
    }
   ],
   "source": [
    "# join country and temperature\n",
    "country_temperature = country_spark.select([\"*\"])\\\n",
    "            .join(temperature_dim, (country_spark.country == upper(temperature_dim.country)), how='full')\\\n",
    "            .select([country_spark.code, country_spark.country, temperature_dim.temperature_id, temperature_dim.average_temperature, temperature_dim.average_temperature_uncertainty])\n",
    "\n",
    "country_temperature.write.parquet(\"s3a://udacity-datalake-msaied2/Project6_Capstone/country_temperature.parquet\", mode=\"overwrite\")\n",
    "print(\"Country_Temperature dimention table writing has been completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "###### Fact table writing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Immigration fact table writing has been completed!\n"
     ]
    }
   ],
   "source": [
    "migrant = spark.read.parquet(\"s3a://udacity-datalake-msaied2/Project6_Capstone/migrant.parquet\")\n",
    "status = spark.read.parquet(\"s3a://udacity-datalake-msaied2/Project6_Capstone/status.parquet\")\n",
    "visa = spark.read.parquet(\"s3a://udacity-datalake-msaied2/Project6_Capstone/visa.parquet\")\n",
    "state = spark.read.parquet(\"s3a://udacity-datalake-msaied2/Project6_Capstone/state.parquet\")\n",
    "time = spark.read.parquet(\"s3a://udacity-datalake-msaied2/Project6_Capstone/time.parquet\")\n",
    "airport = spark.read.parquet(\"s3a://udacity-datalake-msaied2/Project6_Capstone/airport_codes.parquet\")\n",
    "country = spark.read.parquet(\"s3a://udacity-datalake-msaied2/Project6_Capstone/country.parquet\")\n",
    "country_temperature = spark.read.parquet(\"s3a://udacity-datalake-msaied2/Project6_Capstone/country_temperature.parquet\")\n",
    "\n",
    "\n",
    "immigration_fact = immigration_spark.select([\"*\"])\\\n",
    "                .join(airport, (immigration_spark.i94port == airport.ident), how='full')\\\n",
    "                .join(country_temperature, (immigration_spark.i94res == country_temperature.code), how='full')\\\n",
    "                .join(migrant, (immigration_spark.biryear == migrant.birth_year) & (immigration_spark.gender == migrant.gender), how='full')\\\n",
    "                .join(status, (immigration_spark.entdepa == status.arrival_flag) & (immigration_spark.entdepd == status.departure_flag) &\\\n",
    "                      (immigration_spark.matflag == status.match_flag), how='full')\\\n",
    "                .join(visa, (immigration_spark.i94visa == visa.i94visa) & (immigration_spark.visatype == visa.visatype)\\\n",
    "                      & (immigration_spark.visapost == visa.visapost), how='full')\\\n",
    "                .join(state, (immigration_spark.i94addr == state.state_code), how='full')\\\n",
    "                .join(time, (immigration_spark.arrdate == time.arrdate), how='full')\\\n",
    "                .where(col('cicid').isNotNull())\\\n",
    "                .select([\"cicid\", \"i94res\", \"depdate\", \"i94mode\", \"i94port\", \"i94cit\", \"i94addr\", \"airline\", \"fltno\", \"ident\", \"code\",\\\n",
    "                         \"temperature_id\", \"migrant_id\", \"status_flag_id\", \"visa_id\", \"state_code\", time.arrdate.alias(\"arrdate\")])\n",
    "\n",
    "immigration_fact.write.parquet(\"s3a://udacity-datalake-msaied2/Project6_Capstone/immigration.parquet\", mode=\"overwrite\")\n",
    "print(\"Immigration fact table writing has been completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94res</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94port</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>airline</th>\n",
       "      <th>fltno</th>\n",
       "      <th>ident</th>\n",
       "      <th>code</th>\n",
       "      <th>temperature_id</th>\n",
       "      <th>migrant_id</th>\n",
       "      <th>status_flag_id</th>\n",
       "      <th>visa_id</th>\n",
       "      <th>state_code</th>\n",
       "      <th>arrdate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4084316.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>209.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>JL</td>\n",
       "      <td>00782</td>\n",
       "      <td>None</td>\n",
       "      <td>209</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>HI</td>\n",
       "      <td>20566.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4422636.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>20568.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MCA</td>\n",
       "      <td>582.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>*GA</td>\n",
       "      <td>XBLNG</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>TX</td>\n",
       "      <td>20567.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1195600.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>20571.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>OGG</td>\n",
       "      <td>148.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>LH</td>\n",
       "      <td>00464</td>\n",
       "      <td>None</td>\n",
       "      <td>112</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>20551.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5291768.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>20581.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>297.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>QR</td>\n",
       "      <td>00739</td>\n",
       "      <td>None</td>\n",
       "      <td>297</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>CA</td>\n",
       "      <td>20572.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>985523.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>20553.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>CHM</td>\n",
       "      <td>111.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LAND</td>\n",
       "      <td>None</td>\n",
       "      <td>111</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>NY</td>\n",
       "      <td>20550.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cicid  i94res  depdate  i94mode i94port  i94cit i94addr airline  fltno  \\\n",
       "0  4084316.0   209.0  20573.0      1.0     HHW   209.0      HI      JL  00782   \n",
       "1  4422636.0   582.0  20568.0      1.0     MCA   582.0      TX     *GA  XBLNG   \n",
       "2  1195600.0   112.0  20571.0      1.0     OGG   148.0      FL      LH  00464   \n",
       "3  5291768.0   297.0  20581.0      1.0     LOS   297.0      CA      QR  00739   \n",
       "4   985523.0   111.0  20553.0      3.0     CHM   111.0      NY     NaN   LAND   \n",
       "\n",
       "  ident  code temperature_id  migrant_id  status_flag_id  visa_id state_code  \\\n",
       "0  None   209           None           0               0        0         HI   \n",
       "1  None  None           None           1               1        1         TX   \n",
       "2  None   112           None           2               0        0       None   \n",
       "3  None   297           None           3               0        3         CA   \n",
       "4  None   111           None           4               4        0         NY   \n",
       "\n",
       "   arrdate  \n",
       "0  20566.0  \n",
       "1  20567.0  \n",
       "2  20551.0  \n",
       "3  20572.0  \n",
       "4  20550.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immigration = spark.read.parquet(\"s3a://udacity-datalake-msaied2/Project6_Capstone/immigration.parquet\")\n",
    "immigration.toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data quality check passed for immigration with record_count: 1000 records.\n"
     ]
    }
   ],
   "source": [
    "tables = {\n",
    "    \"airport\": airport,\n",
    "    \"country\": country,\n",
    "    \"temperature\": temperature,\n",
    "    \"migrant\": migrant,\n",
    "    \"state\": state,\n",
    "    \"status\": status,\n",
    "    \"time\": time,\n",
    "    \"visa\": visa,\n",
    "    \"immigration\": immigration\n",
    "}\n",
    "\n",
    "for table_name, table in tables.items():\n",
    "    record_count = table.count()\n",
    "\n",
    "    if (record_count == 0):\n",
    "        print(\"Data quality check failed for {} with zero records!\".format(table_name))\n",
    "    else:\n",
    "        print(\"Data quality check passed for {} with record_count: {} records.\".format(table_name, record_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file.\n",
    "\n",
    "### Please refer to Data_Dictionary.txt file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Tools and Technologies\n",
    "1. AWS S3 for data storage\n",
    "2. Pandas for sample data set exploratory data analysis\n",
    "3. PySpark for large data set data processing to transform staging table to dimensional table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Data Update Frequency\n",
    "1. All tables should be update in an append-only mode.\n",
    "2. Demographic readings can be updated annually, while the immigration and temperature readings can be updated on monthly basis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Considerations/Assumptions:\n",
    "##### The data was increased by 100x:\n",
    "We can use more powerful tools for massive data processing and storage like (Amazon EMR & Amazon RedShift)\n",
    "or use nosql techniques like (Apache Cassandra)\n",
    "\n",
    "##### The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    "We can use Apache Airflow to hadle the daily scheduling. Also it can be used to apply data quality checks and get some useful notifications.\n",
    "\n",
    "##### The database needed to be accessed by 100+ people\n",
    "AWS Redshift can handle a massive amount of concurrent sessions. I believe it's worthy to convert the whole solution to be on cloud based if such number of hits will be there.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
